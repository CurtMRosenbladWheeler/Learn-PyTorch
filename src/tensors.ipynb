{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Lesson: Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once PyTorch is installed with `pip install torch`, you can import torch as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/curtwheeler/VisualStudioCode/Learning/Python/PyTorch/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:295: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating Tensors\n",
    "\n",
    "---\n",
    "\n",
    "In PyTorch, one of the simplest ways to create a basic tensor is to use `torch.empty(x, y)`. This function creates a tensor with dimensions `x` by `y`, where each position in the tensor can hold a value. A tensor is essentially a multi-dimensional array, similar to a matrix in math, that can store a list of values across rows and columns. \n",
    "\n",
    "### Understanding `torch.empty(x, y)`\n",
    "\n",
    "When you call `torch.empty(x, y)`, PyTorch allocates memory for a tensor of size `(x, y)`—that is, a tensor with `x` rows and `y` columns. However, this memory space is **not initialized with any values**. Unlike functions like `torch.zeros(x, y)`, which would fill each element with zero, `torch.empty(x, y)` skips the initialization step, leaving the elements filled with whatever was previously in that section of memory.\n",
    "\n",
    "Mathematically, if you imagine a tensor created with `torch.zeros(2, 3)`, it might look like this:\n",
    "\n",
    "\n",
    "\\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}\n",
    "\n",
    "\n",
    "In contrast, a tensor created with `torch.empty(2, 3)` might look like this:\n",
    "\n",
    "\n",
    "\\begin{bmatrix} 3.4 \\times 10^{38} & 0.0000 & -1.2 \\times 10^{37} \\\\ 1.6 \\times 10^{27} & -4.9 & 7.3 \\end{bmatrix}\n",
    "\n",
    "\n",
    "These random, “garbage” values are arbitrary data from memory that PyTorch has not overwritten.\n",
    "\n",
    "#### Why Use `torch.empty`?\n",
    "\n",
    "Since no values are assigned when using `torch.empty(x, y)`, it can be faster than initializing with zeros or other specific values. This approach is helpful when you plan to immediately overwrite the values in the tensor, as no unnecessary work is done in setting initial values that will be discarded.\n",
    "\n",
    "### Data Types of Tensors\n",
    "\n",
    "By default, PyTorch tensors use 32-bit floating-point numbers, which are standard for many machine learning tasks. This means each number in the tensor occupies 32 bits (4 bytes) in memory, following the IEEE 754 standard. In this standard:\n",
    "- 1 bit is reserved for the **sign** (0 for positive, 1 for negative).\n",
    "- 8 bits are for the **exponent**, which determines the range.\n",
    "- 23 bits are for the **mantissa (or significand)**, which represents the precision of the number.\n",
    "\n",
    "With this structure, a 32-bit floating-point number can represent very small and very large values efficiently but has limitations in terms of precision.\n",
    "\n",
    "### Other Data Types Supported by PyTorch\n",
    "\n",
    "PyTorch supports a variety of data types for different needs, as outlined below:\n",
    "\n",
    "| Category         | Data Type       | Description                        | Alias (if any)  |\n",
    "|------------------|-----------------|------------------------------------|-----------------|\n",
    "| Floating-point   | `torch.float32` | 32-bit floating-point              | `torch.float`   |\n",
    "|                  | `torch.float64` | 64-bit floating-point (higher precision) | `torch.double` |\n",
    "|                  | `torch.float16` | 16-bit floating-point (lower precision, faster) | `torch.half`   |\n",
    "|                  | `torch.bfloat16`| 16-bit brain floating-point (special format) |               |\n",
    "| Integer          | `torch.int8`    | 8-bit signed integer               |                 |\n",
    "|                  | `torch.int16`   | 16-bit signed integer              | `torch.short`   |\n",
    "|                  | `torch.int32`   | 32-bit signed integer              | `torch.int`     |\n",
    "|                  | `torch.int64`   | 64-bit signed integer              | `torch.long`    |\n",
    "|                  | `torch.uint8`   | 8-bit unsigned integer             |                 |\n",
    "| Complex          | `torch.complex32` | 32-bit complex number           |                 |\n",
    "|                  | `torch.complex64` | 64-bit complex number           |                 |\n",
    "|                  | `torch.complex128`| 128-bit complex number          |                 |\n",
    "| Boolean          | `torch.bool`    | Boolean (True/False)               |                 |\n",
    "| Quantized        | `torch.qint8`   | Quantized 8-bit signed integer     |                 |\n",
    "|                  | `torch.quint8`  | Quantized 8-bit unsigned integer   |                 |\n",
    "|                  | `torch.qint32`  | Quantized 32-bit signed integer    |                 |\n",
    "|                  | `torch.quint4x2`| Quantized 4-bit unsigned integer (packed) |     |\n",
    "| Special          | `torch.float8_e5m2` | 8-bit floating-point (experimental) |      |\n",
    "|                  | `torch.float8_e4m3fn`| 8-bit floating-point (experimental) |     |\n",
    "\n",
    "Each of these data types can be chosen based on the balance you want between memory usage and precision. For instance, floating-point numbers (`torch.float32`) are common for neural networks, as they provide good precision with reasonable memory usage. Integer types are often used for indexing or counting, while lower-precision types (e.g., `torch.float16`) may be used to save memory in applications where precision is less critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas `torch.zeros(x, y)` initializes a tensor of dimensions `(x, y)` with `0.` (`0.0`) 16-bit floating point values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here’s a description of `torch.ones` and `torch.rand` using mathematical notation.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. `torch.ones(x, y)`\n",
    "\n",
    "The function `torch.ones(x, y)` creates a tensor of shape $(x, y)$ in which **every element is initialized to 1**. This can be expressed as:\n",
    "\n",
    "$$\n",
    "\\mathbf{T} = \\begin{bmatrix} 1 & 1 & \\cdots & 1 \\\\ 1 & 1 & \\cdots & 1 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & 1 & \\cdots & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{T}$ is an $x \\times y$ matrix in which every entry $T_{ij} = 1$ for all $i \\in \\{1, \\dots, x\\}$ and $j \\in \\{1, \\dots, y\\}$.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. `torch.rand(x, y)`\n",
    "\n",
    "The function `torch.rand(x, y)` generates a tensor of shape $(x, y)$ where each element is a **random value drawn from a uniform distribution** over the interval $[0, 1)$. This can be mathematically represented as:\n",
    "\n",
    "$$\n",
    "\\mathbf{R} = \\begin{bmatrix} r_{11} & r_{12} & \\cdots & r_{1y} \\\\ r_{21} & r_{22} & \\cdots & r_{2y} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ r_{x1} & r_{x2} & \\cdots & r_{xy} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The element $r_{ij}$ is sampled such that $r_{ij} \\in [0, 1)$.\n",
    "\n",
    "---\n",
    "\n",
    "### Setting the Random Seed with `torch.manual_seed`\n",
    "\n",
    "To ensure the matrix $\\mathbf{R}$ remains consistent across different runs (i.e., the same values $ r_{ij} $ are generated each time), `torch.manual_seed(seed)` is used. Setting a random seed makes the sequence of random values reproducible, which is useful for consistent debugging and result verification in machine learning experiments. \n",
    "\n",
    "--- \n",
    "\n",
    "This mathematical format provides a structured way to visualize the outputs from `torch.ones` and `torch.rand` without needing specific example values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0290, 0.4019, 0.2598, 0.3666, 0.0583, 0.7006, 0.0518, 0.4681, 0.6738,\n",
       "         0.3315],\n",
       "        [0.7837, 0.5631, 0.7749, 0.8208, 0.2793, 0.6817, 0.2837, 0.6567, 0.2388,\n",
       "         0.7313],\n",
       "        [0.6012, 0.3043, 0.2548, 0.6294, 0.9665, 0.7399, 0.4517, 0.4757, 0.7842,\n",
       "         0.1525],\n",
       "        [0.6662, 0.3343, 0.7893, 0.3216, 0.5247, 0.6688, 0.8436, 0.4265, 0.9561,\n",
       "         0.0770],\n",
       "        [0.4108, 0.0014, 0.5414, 0.6419, 0.2976, 0.7077, 0.4189, 0.0655, 0.8839,\n",
       "         0.8083]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.rand(5,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the Difference Between a Tensor and a Vector?\n",
    "\n",
    "In mathematics and machine learning, **tensors** and **vectors** are both important tools for representing data, but they differ in structure, dimensionality, and how they are used.\n",
    "\n",
    "#### 1. Definition of a Vector\n",
    "\n",
    "A **vector** is a specific type of tensor—one that is restricted to a single dimension. You can think of a vector as a list of numbers arranged in a straight line. Mathematically, vectors represent quantities with both magnitude and direction, and are commonly used in physics, geometry, and machine learning to describe entities like velocity, force, and weight.\n",
    "\n",
    "In PyTorch, a vector might look like this:\n",
    "\n",
    "\n",
    "\\text{vector} = \\begin{bmatrix} 1.5, 2.3, -0.7, 4.0 \\end{bmatrix}\n",
    "\n",
    "\n",
    "This is a **1-dimensional tensor** with 4 elements. We can represent a vector by using a tensor with shape `(4,)`, which has just one dimension of length 4.\n",
    "\n",
    "#### 2. Definition of a Tensor\n",
    "\n",
    "A **tensor** is a more general concept that can represent data in multiple dimensions. Tensors can be thought of as multi-dimensional arrays:\n",
    "- A **0-dimensional tensor** is a single scalar value, like `5.0`.\n",
    "- A **1-dimensional tensor** is a vector, as we discussed above.\n",
    "- A **2-dimensional tensor** is similar to a matrix, with rows and columns, like a spreadsheet or grid of numbers.\n",
    "- Higher-dimensional tensors (3D, 4D, etc.) can be used to represent even more complex structures. For example, a 3D tensor might represent a stack of matrices (like an RGB image), and a 4D tensor might represent a batch of images with color channels.\n",
    "\n",
    "In PyTorch, a 2-dimensional tensor (matrix) might look like this:\n",
    "\n",
    "\n",
    "\\text{tensor} = \\begin{bmatrix} 1.0 & -2.1 \\\\ 0.3 & 4.5 \\end{bmatrix}\n",
    "\n",
    "\n",
    "This is a **2-dimensional tensor** with shape `(2, 2)`, having 2 rows and 2 columns.\n",
    "\n",
    "#### 3. Comparing Tensors and Vectors\n",
    "\n",
    "| Aspect                  | Vector                                      | Tensor                                         |\n",
    "|-------------------------|---------------------------------------------|------------------------------------------------|\n",
    "| **Dimensions**          | 1-dimensional only                          | Can have any number of dimensions (1D, 2D, 3D, etc.) |\n",
    "| **Shape Example**       | `(4,)`                                      | `(2, 2)` for a 2D tensor, `(3, 3, 3)` for a 3D tensor |\n",
    "| **Use Cases**           | Representing simple lists of values         | Representing more complex, multi-dimensional data |\n",
    "| **Example in PyTorch**  | `torch.tensor([1.5, 2.3, -0.7, 4.0])`       | `torch.tensor([[1.0, -2.1], [0.3, 4.5]])`            |\n",
    "\n",
    "In short:\n",
    "- **Vectors are one-dimensional tensors** used to represent lists or sequences of values.\n",
    "- **Tensors are generalized to multiple dimensions**, making them suitable for complex data structures. \n",
    "\n",
    "#### 4. When to Use Each\n",
    "\n",
    "- **Vectors** are ideal for representing simple data, such as features of a single data point (e.g., a list of measurements).\n",
    "- **Tensors** are essential for handling complex data, such as images, videos, or batches of multiple data points in machine learning, where multi-dimensional representations are crucial.\n",
    "\n",
    "In machine learning frameworks like PyTorch, vectors and tensors are essentially both handled as tensors, with vectors just being special cases with a single dimension. Understanding this distinction can help you choose the right structure and shape for your data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
